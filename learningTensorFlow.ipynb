{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORG49aQ/x4XmO07DW5yWg5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mistryvivek/Music-Xmas-Project/blob/master/learningTensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D046BCSAMUZs",
        "outputId": "b828853d-650f-4af8-814c-f04432de70cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "#Only requried on collab"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.version) #make sure its the one you set."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kcfYjHdMeet",
        "outputId": "0d3b59c2-0480-4731-93a3-d87bda03c08f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<module 'tensorflow._api.v2.version' from '/usr/local/lib/python3.9/dist-packages/tensorflow/_api/v2/version/__init__.py'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Examples of tensors"
      ],
      "metadata": {
        "id": "4mbUoiidNuwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "string = tf.Variable(\"this is a string\", tf.string)\n",
        "number = tf.Variable(324, tf.int16)\n",
        "floating = tf.Variable(3.567, tf.float64)"
      ],
      "metadata": {
        "id": "381SxsLUNd2d"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rank\n",
        "\n",
        "* Number of dimensions in the tensor."
      ],
      "metadata": {
        "id": "0ivP439MOBKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rank1_tensor = tf.Variable([\"Test\", \"Ok\", \"Tim\"], tf.string)\n",
        "rank2_tensor = tf.Variable([[\"test\", \"ok\"], [\"test\", \"yes\"]], tf.string)"
      ],
      "metadata": {
        "id": "z58kCdXuOG7Q"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.rank(rank1_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zkuSIyPOVQR",
        "outputId": "da2c01b5-8b3b-4e00-ee86-a4df16242463"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=1>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.rank(rank2_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvNjFT4_ObFm",
        "outputId": "4e8bb20d-ebf7-4d11-8869-172fdedcee9e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Numpy = - tells us the rank"
      ],
      "metadata": {
        "id": "GM36hs2NOeUX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Shape of the tensor "
      ],
      "metadata": {
        "id": "x22EYYL1Omqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rank2_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNfgS_PgOo7c",
        "outputId": "74f81f54-7f3b-4bd5-e86d-b3164f0b8f4b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor must have same amount of items within every sublist."
      ],
      "metadata": {
        "id": "rECj2fDtO1WM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Changing shapes\n",
        "\n"
      ],
      "metadata": {
        "id": "19HCWLTmPCYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create tensor of ones with given dimensions.\n",
        "tensor1 = tf.ones([1,2,3])\n",
        "#One list with 2 sublists all containing 3 variables.\n",
        "tensor1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXsvkQLqPECe",
        "outputId": "da4eff64-972d-42bd-ba6c-017c1e7eafe7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2, 3), dtype=float32, numpy=\n",
              "array([[[1., 1., 1.],\n",
              "        [1., 1., 1.]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor2 = tf.reshape(tensor1, [2,3,1])\n",
        "print(tensor2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpT0FhM5PXLP",
        "outputId": "efbdee8f-1e7c-4552-8118-1ccf0c0d45e3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[1.]\n",
            "  [1.]\n",
            "  [1.]]\n",
            "\n",
            " [[1.]\n",
            "  [1.]\n",
            "  [1.]]], shape=(2, 3, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -1 means that tf should just calculate what you need.\n",
        "tensor3 = tf.reshape(tensor2, [3, -1])\n",
        "print(tensor3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3E-xzOWPVx7",
        "outputId": "9b62e8ba-468a-4fb0-c616-ed0588ff6633"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1. 1.]\n",
            " [1. 1.]\n",
            " [1. 1.]], shape=(3, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Types of tensor\n",
        "\n",
        "* Variable - only immuttable tensor.\n",
        "* Constant\n",
        "* Placeholder \n",
        "* SparseTensor"
      ],
      "metadata": {
        "id": "S69bnNgRP-L3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Core Learning Algorithms\n",
        "\n",
        "* Linear Regression\n",
        "* Classification \n",
        "* Clustering\n",
        "* Hidden Markov Models"
      ],
      "metadata": {
        "id": "uP47O74KR0hU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sklearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQX-cb3dR-Tj",
        "outputId": "fcca2d66-9e87-4c83-9a88-fed41babf88e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "from six.moves import urllib\n",
        "\n",
        "import tensorflow.compat.v2.feature_column as fc"
      ],
      "metadata": {
        "id": "hWw2hkjpTMbG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset.\n",
        "dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv') # training data\n",
        "dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv') # testing data\n",
        "y_train = dftrain.pop('survived')\n",
        "y_eval = dfeval.pop('survived')"
      ],
      "metadata": {
        "id": "a4UsfJPRTzZO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ar_cXv2jV8A3"
      },
      "source": [
        "###Feature Columns\n",
        "In our dataset we have two different kinds of information: **Categorical and Numeric**\n",
        "\n",
        "Our **categorical data** is anything that is not numeric! For example, the sex column does not use numbers, it uses the words \"male\" and \"female\".\n",
        "\n",
        "Before we continue and create/train a model we must convet our categorical data into numeric data. We can do this by encoding each category with an integer (ex. male = 1, female = 2). \n",
        "\n",
        "Fortunately for us TensorFlow has some tools to help!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck',\n",
        "                       'embark_town', 'alone']\n",
        "NUMERIC_COLUMNS = ['age', 'fare']\n",
        "\n",
        "#Stores different feature columns.\n",
        "feature_columns = []\n",
        "for feature_name in CATEGORICAL_COLUMNS:\n",
        "  # Each unique entry for corresponding names.\n",
        "  vocabulary = dftrain[feature_name].unique()  # gets a list of all unique values from given feature column\n",
        "  feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n",
        "\n",
        "for feature_name in NUMERIC_COLUMNS:\n",
        "  feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n",
        "\n",
        "print(feature_columns) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqfegcVbWrND",
        "outputId": "198d226a-f264-4ac6-9b75-037b0682153f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-16-eb3fb06aeaff>:10: categorical_column_with_vocabulary_list (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n",
            "WARNING:tensorflow:From <ipython-input-16-eb3fb06aeaff>:13: numeric_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='n_siblings_spouses', vocabulary_list=(1, 0, 3, 4, 2, 5, 8), dtype=tf.int64, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='parch', vocabulary_list=(0, 1, 2, 5, 3, 4), dtype=tf.int64, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='class', vocabulary_list=('Third', 'First', 'Second'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='deck', vocabulary_list=('unknown', 'C', 'G', 'A', 'B', 'D', 'F', 'E'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='embark_town', vocabulary_list=('Southampton', 'Cherbourg', 'Queenstown', 'unknown'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='alone', vocabulary_list=('n', 'y'), dtype=tf.string, default_value=-1, num_oov_buckets=0), NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To avoid ram from being overloaded, we feed in data in batches.\n",
        "\n",
        "Epochs (how many times our dataset will see the model). Continuous learning.\n",
        "\n",
        "Sometime we can see the data too much where it is overfitting and it just memorises the training data."
      ],
      "metadata": {
        "id": "axoN_iTgYC2E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Input Function\n",
        "\n",
        "* It converts our pandas dataframe into the tf.data.Dataset."
      ],
      "metadata": {
        "id": "FviucFmAYkjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n",
        "  def input_function():  # inner function, this will be returned\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))  # create tf.data.Dataset object with data and its label\n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(1000)  # randomize order of data\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)  # split dataset into batches of 32 and repeat process for number of epochs\n",
        "    return ds  # return a batch of the dataset\n",
        "  return input_function  # return a function object for use\n",
        "\n",
        "train_input_fn = make_input_fn(dftrain, y_train)  # here we will call the input_function that was returned to us to get a dataset object we can feed to the model\n",
        "eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False) # Just training so just need one epoch and don't need to shuffle."
      ],
      "metadata": {
        "id": "9lBB6EbcY0Eu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the model"
      ],
      "metadata": {
        "id": "1reFGCWjgQiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8-uyfrVgTCO",
        "outputId": "b868ebd6-181a-48cd-e5ab-41a7ddfe0604"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-18-2e594e72ddc0>:1: LinearClassifierV2.__init__ (from tensorflow_estimator.python.estimator.canned.linear) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow_estimator/python/estimator/head/head_utils.py:54: BinaryClassHead.__init__ (from tensorflow_estimator.python.estimator.head.binary_class_head) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow_estimator/python/estimator/canned/linear.py:944: Estimator.__init__ (from tensorflow_estimator.python.estimator.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow_estimator/python/estimator/estimator.py:1842: RunConfig.__init__ (from tensorflow_estimator.python.estimator.run_config) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpwp61dl29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_est.train(train_input_fn)\n",
        "result = linear_est.evaluate(eval_input_fn)"
      ],
      "metadata": {
        "id": "SjNj24GTgxZ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c22d2d70-a11b-4b08-a99c-da051b5c9527"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/training/training_util.py:396: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/keras/optimizers/legacy/ftrl.py:173: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow_estimator/python/estimator/model_fn.py:250: EstimatorSpec.__new__ (from tensorflow_estimator.python.estimator.model_fn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow_estimator/python/estimator/estimator.py:1414: NanTensorHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow_estimator/python/estimator/estimator.py:1417: LoggingTensorHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/training/basic_session_run_hooks.py:232: SecondOrStepTimer.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow_estimator/python/estimator/estimator.py:1454: CheckpointSaverHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/training/monitored_session.py:579: StepCounterHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/training/monitored_session.py:586: SummarySaverHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/training/monitored_session.py:1455: SessionRunArgs.__new__ (from tensorflow.python.training.session_run_hook) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/training/monitored_session.py:1454: SessionRunContext.__init__ (from tensorflow.python.training.session_run_hook) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/training/monitored_session.py:1474: SessionRunValues.__new__ (from tensorflow.python.training.session_run_hook) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/training/evaluation.py:260: FinalOpsHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iyy6lYfDg7xb",
        "outputId": "1e76b53b-7247-4ec4-a0eb-d5953e42c262"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.7462121,\n",
              " 'accuracy_baseline': 0.625,\n",
              " 'auc': 0.8318334,\n",
              " 'auc_precision_recall': 0.7772095,\n",
              " 'average_loss': 0.4840581,\n",
              " 'label/mean': 0.375,\n",
              " 'loss': 0.47853148,\n",
              " 'precision': 0.65384614,\n",
              " 'prediction/mean': 0.38884237,\n",
              " 'recall': 0.68686867,\n",
              " 'global_step': 200}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification"
      ],
      "metadata": {
        "id": "JAsw0d4mjaV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
        "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
        "# Lets define some constants to help us later on"
      ],
      "metadata": {
        "id": "qwnridWMjbpd"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = tf.keras.utils.get_file(\n",
        "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
        "test_path = tf.keras.utils.get_file(\n",
        "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
        "\n",
        "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
        "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
        "# Here we use keras (a module inside of TensorFlow) to grab our datasets and read them into a pandas dataframe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dXBAZilj5jR",
        "outputId": "6eed1e3b-dfdb-4cb4-a154-2f97b3693965"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\n",
            "2194/2194 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\n",
            "573/573 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = train.pop('Species')\n",
        "test_y = test.pop('Species')"
      ],
      "metadata": {
        "id": "Kp-ihLvhmnyt"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#INPUT FUNCTION\n",
        "def input_fn(features, labels, training=True, batch_size=256):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
        "\n",
        "  if training:\n",
        "    dataset = dataset.shuffle(1000).repeat()\n",
        "  \n",
        "  return dataset.batch(batch_size)\n",
        "\n",
        "#GET FEATURE COLUMNS.\n",
        "my_feature_columns = []\n",
        "for key in train.keys():\n",
        "  my_feature_columns.append(tf.feature_column.numeric_column(key=key))"
      ],
      "metadata": {
        "id": "onNkWRIQj8S-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tensorflow recommend using a DNN.\n",
        "classifier = tf.estimator.DNNClassifier(\n",
        "    feature_columns=my_feature_columns,\n",
        "    hidden_units=[30, 10],\n",
        "    n_classes=3\n",
        ")\n",
        "\n",
        "classifier.train(\n",
        "    input_fn= lambda: input_fn(train, train_y, training=True), steps = 5000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnHn40aklGsY",
        "outputId": "91168e8d-0313-45ce-c292-eccf2668808e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-25-b8db6d2dc578>:2: DNNClassifierV2.__init__ (from tensorflow_estimator.python.estimator.canned.dnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow_estimator/python/estimator/head/head_utils.py:59: MultiClassHead.__init__ (from tensorflow_estimator.python.estimator.head.multi_class_head) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpf84m_7ns\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow_estimator/python/estimator/estimator.py:385: StopAtStepHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7f8c66df79a0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.evaluate(input_fn= lambda: input_fn(test, test_y, training=False), steps = 5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSgk3_gwm0IR",
        "outputId": "8edc409f-9e1c-4f26-f6df-bdaf47e44d30"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.7,\n",
              " 'average_loss': 0.64287555,\n",
              " 'loss': 0.64287555,\n",
              " 'global_step': 5000}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict = {'SepalLength': 2.4, 'SepalWidth': 5.0, 'PetalLength': 4.8, 'PetalWidth': 11.0}\n",
        "predictions = classifier.predict(input_fn=lambda: input_fn(predict))"
      ],
      "metadata": {
        "id": "UTnJxP3xoVAc"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for pred_dict in predictions:\n",
        "    class_id = pred_dict['class_ids'][0]\n",
        "    probability = pred_dict['probabilities'][class_id]\n",
        "\n",
        "    print('Prediction is \"{}\" ({:.1f}%)'.format(\n",
        "        SPECIES[class_id], 100 * probability))"
      ],
      "metadata": {
        "id": "0LtWNUavqWMP"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hidden Markov Functions\n",
        "\n",
        "**States:** In each markov model we have a finite set of states. These states could be something like \"warm\" and \"cold\" or \"high\" and \"low\" or even \"red\", \"green\" and \"blue\". These states are \"hidden\" within the model, which means we do not direcly observe them.\n",
        "\n",
        "**Observations:** Each state has a particular outcome or observation associated with it based on a probability distribution. An example of this is the following: *On a hot day Tim has a 80% chance of being happy and a 20% chance of being sad.*\n",
        "\n",
        "**Transitions:** Each state will have a probability defining the likelyhood of transitioning to a different state. An example is the following: *a cold day has a 30% chance of being followed by a hot day and a 70% chance of being follwed by another cold day.*\n",
        "\n",
        "To create a hidden markov model we need.\n",
        "- States\n",
        "- Observation Distribution\n",
        "- Transition Distribution"
      ],
      "metadata": {
        "id": "dcFShpXXq28z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_probability as tfp  # We are using a different module from tensorflow this time\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "Q-8N-88_q5RD"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Weather Model\n",
        "Taken direclty from the TensorFlow documentation (https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/HiddenMarkovModel). \n",
        "\n",
        "We will model a simple weather system and try to predict the temperature on each day given the following information.\n",
        "1. Cold days are encoded by a 0 and hot days are encoded by a 1.\n",
        "2. The first day in our sequence has an 80% chance of being cold.\n",
        "3. A cold day has a 30% chance of being followed by a hot day.\n",
        "4. A hot day has a 20% chance of being followed by a cold day.\n",
        "5. On each day the temperature is\n",
        " normally distributed with mean and standard deviation 0 and 5 on\n",
        " a cold day and mean and standard deviation 15 and 10 on a hot day.\n",
        "\n",
        "If you're unfamiliar with **standard deviation** it can be put simply as the range of expected values. \n",
        "\n",
        "In this example, on a hot day the average temperature is 15 and ranges from 5 to 25.\n",
        "\n",
        "To model this in TensorFlow we will do the following."
      ],
      "metadata": {
        "id": "UqdqlFwFs7dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfd = tfp.distributions"
      ],
      "metadata": {
        "id": "kT-ncmnos76w"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Refers to point 2.\n",
        "initial_distribution = tfd.Categorical(probs=[0.8, 0.2])"
      ],
      "metadata": {
        "id": "PHLY2iJZtPw3"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Refers to point 3 and 4.\n",
        "transition_distribution = tfd.Categorical(probs=[[0.7, 0.3],\n",
        "                                                 [0.2, 0.8]])"
      ],
      "metadata": {
        "id": "ibRpao5qtZWf"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Refers to point 5.\n",
        "observation_distribution = tfd.Normal(loc = [0., 15.], scale=[5., 10.])"
      ],
      "metadata": {
        "id": "N9WtAMFNtoaK"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tfd.HiddenMarkovModel(\n",
        "    initial_distribution=initial_distribution,\n",
        "    transition_distribution=transition_distribution,\n",
        "    observation_distribution=observation_distribution,\n",
        "    num_steps=7) #How many days we want to model for."
      ],
      "metadata": {
        "id": "h5hFNXPut1oV"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean = model.mean()\n",
        "\n",
        "with tf.compat.v1.Session() as sess:\n",
        "  print(mean.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C96IUcQyt6Mw",
        "outputId": "cd26510a-0944-405d-97c0-2f51a70007e7"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3.        5.9999995 7.4999995 8.25      8.625001  8.812501  8.90625  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Networks"
      ],
      "metadata": {
        "id": "F1q12wn2ywcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "fashion_mnist = keras.datasets.fashion_mnist # Pixel data about database of clothes.\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "y2h0XR9EyyZ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af7096e0-0619-44df-b8c2-358a37fc8622"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MARr4vXZBnJx",
        "outputId": "e45a781d-b8b2-4de4-9fc0-08a253b6d442"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hdpe8FDdCtEE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}